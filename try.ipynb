{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cd .config/Ultralytics\n",
    "vim settings.yaml\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆ≠ÁªÉ\n",
    "experiment_name = 'b160s-C2f_SCConv_b23_Triplet_v1_c' # \n",
    "!python train.py --yaml ultralytics/models/v8/yolov8s-C2f_SCConv_b23_Triplet_v1_c.yaml \\\n",
    "    --data datasets/luderick_base/luderick_base.yaml \\\n",
    "    --workers 8 --batch 16 --name {experiment_name} \\\n",
    "    --epochs 160 --unamp # --resume runs/train/{experiment_name}/weights/last.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# È™åËØÅ\n",
    "experiment_name = 'b150s-baseline_3080' # \n",
    "!yolo val model=runs/train/{experiment_name}/weights/best.pt \\\n",
    "    data=datasets/luderick_base/luderick_base.yaml save_json=True \\\n",
    "    split='val'  project=runs/val/{experiment_name}/ # batch=1 # name={experiment_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆ°ÁÆócocoÊåáÊ†á\n",
    "!python cal_coco_metrice.py --anno_json datasets/luderick_base/val_coco.json --pred_json runs/val/{experiment_name}/val/predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆ°ÁÆóFPS\n",
    "experiment_name = 'b120s_baseline' # \n",
    "!python get_FPS.py --weights runs/train/{experiment_name}/weights/best.pt --batch 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÈÖçÁΩÆÊñá‰ª∂ÊµãËØï\n",
    "!python train.py --info --yaml ultralytics/models/v8/yolov8-C2f-DLKA.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val.pyÈ™åËØÅ\n",
    "experiment_name = 'b150s_baseline' # \n",
    "!python val.py --weight runs/train/{experiment_name}/weights/best.pt \\\n",
    "    --data datasets/luderick_base/luderick_base.yaml --save_json \\\n",
    "    --split 'val' --name {experiment_name}/val # --batch 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Ultralytics settings reset to default values. This may be due to a possible problem with your settings or a recent ultralytics package update. \n",
      "View settings with 'yolo settings' or at '/home/ubuntu/.config/Ultralytics/settings.yaml'\n",
      "Update settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'.\n",
      "Ultralytics YOLOv8.0.202 üöÄ Python-3.8.17 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/ultralytics/datasets/luderick_base/labels/val... 824 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/ubuntu/ultralytics/datasets/luderick_base/labels/val.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        824       1632      0.888      0.865      0.914      0.618\n",
      "Speed: 0.6ms preprocess, 3.7ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Saving runs/val/b160s-baseline/val3/predictions.json...\n",
      "Results saved to \u001b[1mruns/val/b160s-baseline/val3\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.671\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
      "\n",
      "IOU:0.5 MAP:0.900 Recall:0.954\n",
      "\n",
      "IOU:0.55 MAP:0.883 Recall:0.940\n",
      "\n",
      "IOU:0.6 MAP:0.862 Recall:0.920\n",
      "\n",
      "IOU:0.65 MAP:0.824 Recall:0.888\n",
      "\n",
      "IOU:0.7 MAP:0.760 Recall:0.833\n",
      "\n",
      "IOU:0.75 MAP:0.671 Recall:0.756\n",
      "\n",
      "IOU:0.8 MAP:0.537 Recall:0.632\n",
      "\n",
      "IOU:0.85 MAP:0.351 Recall:0.455\n",
      "Ultralytics YOLOv8.0.202 üöÄ Python-3.8.17 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "YOLOv8s-C2f_SCConv_b2_c summary (fused): 188 layers, 11273683 parameters, 0 gradients, 29.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/ultralytics/datasets/luderick_base/labels/val.cache..\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        824       1632      0.876      0.877      0.922      0.624\n",
      "Speed: 0.2ms preprocess, 3.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Saving runs/val/b160s-C2f_SCConv_b2_c/val2/predictions.json...\n",
      "Results saved to \u001b[1mruns/val/b160s-C2f_SCConv_b2_c/val2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.690\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.653\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
      "\n",
      "IOU:0.5 MAP:0.916 Recall:0.972\n",
      "\n",
      "IOU:0.55 MAP:0.896 Recall:0.957\n",
      "\n",
      "IOU:0.6 MAP:0.881 Recall:0.942\n",
      "\n",
      "IOU:0.65 MAP:0.851 Recall:0.919\n",
      "\n",
      "IOU:0.7 MAP:0.795 Recall:0.866\n",
      "\n",
      "IOU:0.75 MAP:0.690 Recall:0.770\n",
      "\n",
      "IOU:0.8 MAP:0.564 Recall:0.659\n",
      "\n",
      "IOU:0.85 MAP:0.364 Recall:0.471\n",
      "Ultralytics YOLOv8.0.202 üöÄ Python-3.8.17 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "YOLOv8s-TripletAttention_v1_c summary (fused): 212 layers, 11126771 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/ultralytics/datasets/luderick_base/labels/val.cache..\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        824       1632      0.885      0.854      0.921      0.631\n",
      "Speed: 0.2ms preprocess, 3.6ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Saving runs/val/b160s-TripletAttention_v1_c/val2/predictions.json...\n",
      "Results saved to \u001b[1mruns/val/b160s-TripletAttention_v1_c/val2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.910\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.652\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
      "\n",
      "IOU:0.5 MAP:0.910 Recall:0.964\n",
      "\n",
      "IOU:0.55 MAP:0.892 Recall:0.947\n",
      "\n",
      "IOU:0.6 MAP:0.874 Recall:0.931\n",
      "\n",
      "IOU:0.65 MAP:0.835 Recall:0.896\n",
      "\n",
      "IOU:0.7 MAP:0.776 Recall:0.843\n",
      "\n",
      "IOU:0.75 MAP:0.688 Recall:0.763\n",
      "\n",
      "IOU:0.8 MAP:0.571 Recall:0.657\n",
      "\n",
      "IOU:0.85 MAP:0.388 Recall:0.483\n",
      "Ultralytics YOLOv8.0.202 üöÄ Python-3.8.17 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "YOLOv8s-C2f_SCConv_b2_Triplet_v1_c summary (fused): 232 layers, 11274483 parameters, 0 gradients, 29.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/ultralytics/datasets/luderick_base/labels/val.cache..\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        824       1632      0.879      0.883       0.93      0.639\n",
      "Speed: 0.2ms preprocess, 4.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Saving runs/val/b160s-C2f_SCConv_b2_Triplet_v1_c/val2/predictions.json...\n",
      "Results saved to \u001b[1mruns/val/b160s-C2f_SCConv_b2_Triplet_v1_c/val2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.922\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.702\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.655\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
      "\n",
      "IOU:0.5 MAP:0.922 Recall:0.971\n",
      "\n",
      "IOU:0.55 MAP:0.903 Recall:0.956\n",
      "\n",
      "IOU:0.6 MAP:0.880 Recall:0.938\n",
      "\n",
      "IOU:0.65 MAP:0.851 Recall:0.911\n",
      "\n",
      "IOU:0.7 MAP:0.794 Recall:0.861\n",
      "\n",
      "IOU:0.75 MAP:0.702 Recall:0.780\n",
      "\n",
      "IOU:0.8 MAP:0.582 Recall:0.662\n",
      "\n",
      "IOU:0.85 MAP:0.384 Recall:0.488\n"
     ]
    }
   ],
   "source": [
    "# Ëá™ÂÆö‰πâÊµãËØï 8.0.202\n",
    "experiment_name = 'b160s-baseline' # \n",
    "!yolo val model=runs/train/{experiment_name}/weights/best.pt \\\n",
    "    data=datasets/luderick_base/luderick_base.yaml save_json=True \\\n",
    "    split='val'  project=runs/val/{experiment_name}/ # batch=1 # name={experiment_name}\n",
    "!python cal_coco_metrice.py --anno_json datasets/luderick_base/val_coco.json --pred_json runs/val/{experiment_name}/val/predictions.json\n",
    "\n",
    "experiment_name = 'b160s-C2f_SCConv_b2_c' # \n",
    "!yolo val model=runs/train/{experiment_name}/weights/best.pt \\\n",
    "    data=datasets/luderick_base/luderick_base.yaml save_json=True \\\n",
    "    split='val'  project=runs/val/{experiment_name}/ # batch=1 # name={experiment_name}\n",
    "!python cal_coco_metrice.py --anno_json datasets/luderick_base/val_coco.json --pred_json runs/val/{experiment_name}/val/predictions.json\n",
    "\n",
    "experiment_name = 'b160s-TripletAttention_v1_c' # \n",
    "!yolo val model=runs/train/{experiment_name}/weights/best.pt \\\n",
    "    data=datasets/luderick_base/luderick_base.yaml save_json=True \\\n",
    "    split='val'  project=runs/val/{experiment_name}/ # batch=1 # name={experiment_name}\n",
    "!python cal_coco_metrice.py --anno_json datasets/luderick_base/val_coco.json --pred_json runs/val/{experiment_name}/val/predictions.json\n",
    "\n",
    "experiment_name = 'b160s-C2f_SCConv_b2_Triplet_v1_c' # \n",
    "!yolo val model=runs/train/{experiment_name}/weights/best.pt \\\n",
    "    data=datasets/luderick_base/luderick_base.yaml save_json=True \\\n",
    "    split='val'  project=runs/val/{experiment_name}/ # batch=1 # name={experiment_name}\n",
    "!python cal_coco_metrice.py --anno_json datasets/luderick_base/val_coco.json --pred_json runs/val/{experiment_name}/val/predictions.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.690\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.653\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
      "Traceback (most recent call last):\n",
      "  File \"cal_coco_metrice.py\", line 25, in <module>\n",
      "    categories = coco_gt.getCatIds()  # Ëé∑ÂèñÊâÄÊúâÁ±ªÂà´ÁöÑ ID\n",
      "NameError: name 'coco_gt' is not defined\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'b160s-C2f_SCConv_b2_c' # \n",
    "!python cal_coco_metrice.py --anno_json datasets/luderick_base/val_coco.json --pred_json runs/val/{experiment_name}/val/predictions.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
